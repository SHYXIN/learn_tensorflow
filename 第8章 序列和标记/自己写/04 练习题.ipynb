{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n",
      "tv future in the hands of viewers with home theatre systems plasma high-definition tvs and digital v\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# 停用词\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "# stopwords.append(\"  \")   # 双空格\n",
    "\n",
    "pattern = re.compile('|'.join(stopwords))\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "with open('../tmp/bbc-text.csv', 'r') as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    for row in csv_reader:\n",
    "        label = row['category']\n",
    "        ori_sentence = row['text']\n",
    "        # 删除停用词\n",
    "        for word in stopwords:\n",
    "            stop_word = \" \" + word + \" \"\n",
    "            sentence = ori_sentence.replace(stop_word, \" \")\n",
    "            sentence = sentence.replace(\"  \", \" \")\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label)\n",
    "print(len(labels))  # \n",
    "print(len(sentences))  # \n",
    "print(sentences[0][:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29726\n",
      "<class 'numpy.ndarray'>\n",
      "(2225, 4491)\n",
      "[177 265   7 ...   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index  # 先生成对照表\n",
    "print(len(word_index))  # 大于等于29726 这么多词，\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)  # 根据对照表再将句子转成序列，存在长度不一致的问题\n",
    "\n",
    "padded = pad_sequences(sequences,padding='post')  # 生成统一长度的序列，补齐方式为在后边\n",
    "\n",
    "print(type(padded))  # 类型为np.array\n",
    "print(padded.shape)  # 形状为(2225, 4491)  2225个句子，最长的句子为4491个单词\n",
    "print(padded[0])  # 预览第一条句子对应的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "{'sport': 1, 'business': 2, 'politics': 3, 'tech': 4, 'entertainment': 5}\n"
     ]
    }
   ],
   "source": [
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "label_word_index = label_tokenizer.word_index\n",
    "label_seq = label_tokenizer.texts_to_sequences(labels)  # 因为标签都只是一个字就不需要再统一了\n",
    "print(len(label_seq))\n",
    "print(label_word_index)  # 就五类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfieldnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrestval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mextrasaction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'excel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m      <no docstring>\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\wx847\\anaconda3\\envs\\learn_tensorflow\\lib\\csv.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "datas = [{'name': 'Bob', 'age': 23},{'name': 'Jerry', 'age': 44},{'name': 'Tom', 'age': 15} ]\n",
    " \n",
    "# with open('test_csv_data.csv', 'w', newline='') as f:\n",
    "#      writer = csv.DictWriter(f, ['name', 'age'])# 标头在这里传入,作为第一行数据\n",
    "#      writer.writeheader()\n",
    "#      for row in datas:\n",
    "#         writer.writerow(row)\n",
    "?csv.DictWriter"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b34fee034e6c6559cf1b732e166f57ae608166b2226a83e90a4ecbc0876e39"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
